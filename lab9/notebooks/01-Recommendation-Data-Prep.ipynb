{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation - Data Preparation 🎬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn-images-1.medium.com/max/1200/0*ePGWILY6GyplT-nn\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next few challenges, you will build a powerful **movie recommender**.\n",
    "\n",
    "We will use the open-source library [LightFM](https://github.com/lyst/lightfm) which provides easy python implementation of **hybrid** recommendation engines.\n",
    "\n",
    "In this first part, we will prepare the data in order to train efficiently of the model.\n",
    "\n",
    "We let you load the data `movies` and `ratings` downloaded from the **small** [movielens dataset](https://grouplens.org/datasets/movielens/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.sparse import coo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1                   Adventure|Children|Fantasy  \n",
      "2                               Comedy|Romance  \n",
      "3                         Comedy|Drama|Romance  \n",
      "4                                       Comedy  \n",
      "   userId  movieId  rating  timestamp\n",
      "0       1        1     4.0  964982703\n",
      "1       1        3     4.0  964981247\n",
      "2       1        6     4.0  964982224\n",
      "3       1       47     5.0  964983815\n",
      "4       1       50     5.0  964982931\n"
     ]
    }
   ],
   "source": [
    "### TODO: Load the movies and ratings datasets\n",
    "movies = pd.read_csv('ml-latest-small/movies.csv')\n",
    "ratings = pd.read_csv('ml-latest-small/ratings.csv')\n",
    "\n",
    "# Display the first few rows of each DataFrame to ensure they are loaded correctly\n",
    "print(movies.head())\n",
    "print(ratings.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1**. What are the different types of recommendation models? Explain briefly with your own words the differences between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several types of recommendation models, each with its own approach to suggesting items to users. The main types are:\n",
    ">##### **1. Content-Based Filtering**\n",
    ">>Content-based filtering recommends items similar to those the user has liked in the past. It relies on item features and user preferences. For example, if a user likes action movies, the system will recommend other action movies.\n",
    ">>##### **Pros:**\n",
    ">>Doesn't require data from other users.\n",
    ">>Can start making recommendations immediately.\n",
    ">>##### **Cons:**\n",
    ">>Limited by the features used to describe items.\n",
    ">>May not recommend items outside the user's established preferences.\n",
    ">##### **2. Collaborative Filtering**\n",
    ">>Collaborative filtering makes recommendations based on the preferences of similar users. There are two main types:\n",
    "User-based Collaborative Filtering: Finds users similar to the target user and recommends items they have liked.\n",
    "Item-based Collaborative Filtering: Finds items similar to those the target user has liked and recommends them.\n",
    ">>##### **Pros:**\n",
    ">>Can uncover hidden patterns and preferences.\n",
    ">>Effective when there is a lot of user interaction data.\n",
    ">>##### **Cons:**\n",
    ">>Requires a large amount of data.\n",
    ">>Suffers from the cold start problem for new users and items.\n",
    ">##### **3. Matrix Factorization**\n",
    ">>Matrix factorization decomposes the user-item interaction matrix into lower-dimensional matrices. This helps in discovering latent features that explain observed interactions. Popular techniques include Singular Value Decomposition (SVD) and Alternating Least Squares (ALS).\n",
    ">>##### **Pros:**\n",
    ">>Can handle large-scale data.\n",
    ">>Effective in uncovering latent features.\n",
    ">>##### **Cons:**\n",
    ">>Computationally intensive.\n",
    ">>Requires a good amount of data.\n",
    ">##### **4. Hybrid Models**\n",
    ">>Hybrid models combine multiple recommendation strategies to leverage their individual strengths. For example, a hybrid model might use both content-based and collaborative filtering to improve recommendations.\n",
    ">>##### **Pros:**\n",
    ">>Can provide more accurate recommendations.\n",
    ">>Mitigates the weaknesses of individual models.\n",
    ">>##### **Cons:**\n",
    ">>More complex to implement and maintain.\n",
    ">>Can be computationally expensive.\n",
    ">##### **5. Deep Learning-based Models**\n",
    ">>These models use neural networks to capture complex patterns in the data. Examples include autoencoders, convolutional neural networks (CNNs), and recurrent neural networks (RNNs).\n",
    ">>##### **Pros**:\n",
    ">>Can handle complex and high-dimensional data.\n",
    ">>Capable of capturing intricate relationships.\n",
    ">>##### **Cons**:\n",
    ">>Requires a large amount of data and computational resources.\n",
    ">>Complex to train and fine-tune."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1bis**. What data is expected by the LightFM `fit` method? Especially, how does the train data should be organized, and what should be the type of the train dataset? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LightFM fit method expects the training data to be in the form of an interaction matrix. Here's a detailed explanation of what data is expected and how it should be organized:\n",
    "\n",
    ">#### **Interaction Matrix**\n",
    ">The interaction matrix represents the interactions between users and items. Each entry in the matrix indicates whether a user has interacted with an item (e.g., rated it, viewed it, liked it, etc.) and possibly the strength of that interaction (e.g., rating score).\n",
    "\n",
    ">>##### **Format:**\n",
    "\n",
    ">>>- Type: The interaction matrix should be a sparse matrix. LightFM works with scipy's csr_matrix (Compressed Sparse Row format) or coo_matrix (Coordinate format).\n",
    ">>>- Shape: The matrix should have a shape of (number of users, number of items).\n",
    ">>##### **Creating the Interaction Matrix**\n",
    ">>To create the interaction matrix, you'll typically start with a dataset of user-item interactions. Here’s how you can create and organize this data:\n",
    "\n",
    ">>>- Load Data:\n",
    ">>>Load your user-item interactions into a pandas DataFrame. This should include at least user IDs, item IDs, and interaction values (e.g., ratings).\n",
    "\n",
    ">>>- Encode Users and Items:\n",
    ">>>Convert the user IDs and item IDs into integer indices that will be used to index the interaction matrix.\n",
    "\n",
    ">>>- Build Sparse Matrix:\n",
    ">>>Use the csr_matrix or coo_matrix from scipy to create the interaction matrix. Each non-zero entry in this matrix represents an interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7a1fc028d950>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode user IDs and item IDs\n",
    "user_ids = ratings['userId'].astype('category').cat.codes\n",
    "item_ids = ratings['movieId'].astype('category').cat.codes\n",
    "\n",
    "# Create interaction matrix\n",
    "interaction_matrix = coo_matrix(\n",
    "    (ratings['rating'], (user_ids, item_ids)),\n",
    "    shape=(user_ids.max() + 1, item_ids.max() + 1)\n",
    ")\n",
    "\n",
    "# Now you can use the interaction_matrix with LightFM\n",
    "from lightfm import LightFM\n",
    "\n",
    "model = LightFM(loss='warp')\n",
    "model.fit(interaction_matrix, epochs=30, num_threads=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2**. Explore `movies` and `ratings`, what do those datasets contain? How are they organized?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Exploring the movies Dataset**\n",
    "The movies dataset typically contains information about the movies, such as movie IDs, titles, and genres.\n",
    "\n",
    "- movieId: A unique identifier for each movie.\n",
    "- title: The title of the movie, often including the release year.\n",
    "- genres: A pipe-separated list of genres associated with the movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Movies DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9742 entries, 0 to 9741\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   movieId  9742 non-null   int64 \n",
      " 1   title    9742 non-null   object\n",
      " 2   genres   9742 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 228.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMovies DataFrame Info:\")\n",
    "print(movies.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Exploring the ratings Dataset**\n",
    "The ratings dataset contains user interactions with the movies, such as ratings.\n",
    "\n",
    "- userId: A unique identifier for each user.\n",
    "- movieId: A unique identifier for each movie (corresponds to the movieId in the movies dataset).\n",
    "- rating: The rating given by the user to the movie, typically on a scale from 0.5 to 5.0.\n",
    "- timestamp: The time when the rating was given, represented as a Unix timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ratings DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100836 entries, 0 to 100835\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   userId     100836 non-null  int64  \n",
      " 1   movieId    100836 non-null  int64  \n",
      " 2   rating     100836 non-null  float64\n",
      " 3   timestamp  100836 non-null  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 3.1 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRatings DataFrame Info:\")\n",
    "print(ratings.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 & Q4 are optional\n",
    "> you can come back to it if you have time after having finished the whole project of the day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a few utils functions for you in `utils.py` script. Especially:\n",
    "- `threshold_interactions_df`:\n",
    "> Limit interactions df to minimum row and column interactions\n",
    "\n",
    "**Q3**. Open `src/utils.py` file, and have a look at the documentation of this function to understand its goal and how it works.\n",
    "\n",
    "Have a look the code to understand fully how it works. You should be familiar with everything.\n",
    "\n",
    "What does represent the variable `sparsity`? What is the range of values in which sparsity can be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4**. Create a new DataFrame `ratings_thresh`, that filters `ratings` with only:\n",
    "- users that rated strictly more than 4 movies\n",
    "- movies that have been rated at least 10 times\n",
    "\n",
    "How many users/movies remain in this new dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5**. In order to fit a [LightFM](https://lyst.github.io/lightfm/docs/home.html) model, we need to transform our Dataframe to a sparse matrix (cf. below). This is not straightforward so we included the function `df_to_matrix` in `utils.py`.\n",
    "\n",
    "> 🔦 **Hint**:  Sparse matrices are just **big matrices with a lot of zeros or empty values**.\n",
    "> \n",
    "> Existing tools (Pandas DataFrame, Numpy arrays for example) are not suitable for manipulating this kind of data. So we will use [Scipy sparse matrices](https://docs.scipy.org/doc/scipy-0.14.0/reference/sparse.html).\n",
    ">\n",
    "> It exists many different \"types\" of sparse matrices (CSC, CSR, COO, DIA, etc.). You don't need to know them. Just know that it corresponds to different formats with different methods of manipulation, slicing, indexing, etc.\n",
    "\n",
    "> 🔦 **Hint 2**:  By going from a DataFrame to a sparse matrix, you will lose the information of the ids (userId and movieId), you will only deal with indices (row number and column number). Therefore, the `df_to_matrix` function also returns dictionaries mapping indexes to ids (ex: uid_to_idx mapping userId to index of the matrix) \n",
    "\n",
    "\n",
    "Have a look at the util function documentation, and use it to create 5 new variables:\n",
    "- a final sparse matrix `ratings_matrix` (this will be the data used to train the model)\n",
    "- the following utils mappers:\n",
    "    - `uid_to_idx`\n",
    "    - `idx_to_uid`\n",
    "    - `mid_to_idx`\n",
    "    - `idx_to_mid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the ratings matrix: (610, 9724)\n",
      "User ID to Index mapping: [(1, 0), (2, 1), (3, 2), (4, 3), (5, 4)]\n",
      "Index to User ID mapping: [(0, 1), (1, 2), (2, 3), (3, 4), (4, 5)]\n",
      "Movie ID to Index mapping: [(1, 0), (3, 1), (6, 2), (47, 3), (50, 4)]\n",
      "Index to Movie ID mapping: [(0, 1), (1, 3), (2, 6), (3, 47), (4, 50)]\n"
     ]
    }
   ],
   "source": [
    "from utils import df_to_matrix\n",
    "\n",
    "ratings_matrix, uid_to_idx, idx_to_uid, mid_to_idx, idx_to_mid = df_to_matrix(ratings, 'userId', 'movieId')\n",
    "\n",
    "print(f\"Shape of the ratings matrix: {ratings_matrix.shape}\")\n",
    "print(f\"User ID to Index mapping: {list(uid_to_idx.items())[:5]}\")\n",
    "print(f\"Index to User ID mapping: {list(idx_to_uid.items())[:5]}\")\n",
    "print(f\"Movie ID to Index mapping: {list(mid_to_idx.items())[:5]}\")\n",
    "print(f\"Index to Movie ID mapping: {list(idx_to_mid.items())[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6**.\n",
    "- On the one side, find what movies did the userId 4 rate?\n",
    "\n",
    "- On the other side, what is the value of `ratings_matrix` for:\n",
    "    - userId = 4 and movieId=1\n",
    "    - userId = 4 and movieId=2\n",
    "    - userId = 4 and movieId=21\n",
    "    - userId = 4 and movieId=32\n",
    "    - userId = 4 and movieId=126\n",
    "\n",
    "Conclude on the values signification in `ratings_matrix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies rated by userId 4: [21, 32, 45, 47, 52, 58, 106, 125, 126, 162, 171, 176, 190, 215, 222, 232, 235, 247, 260, 265, 296, 319, 342, 345, 348, 351, 357, 368, 417, 441, 450, 457, 475, 492, 509, 538, 539, 553, 588, 593, 595, 599, 608, 648, 708, 759, 800, 892, 898, 899, 902, 904, 908, 910, 912, 914, 919, 920, 930, 937, 1025, 1046, 1057, 1060, 1073, 1077, 1079, 1080, 1084, 1086, 1094, 1103, 1136, 1179, 1183, 1188, 1196, 1197, 1198, 1199, 1203, 1211, 1213, 1219, 1225, 1250, 1259, 1265, 1266, 1279, 1282, 1283, 1288, 1291, 1304, 1391, 1449, 1466, 1500, 1517, 1580, 1597, 1617, 1641, 1704, 1719, 1732, 1733, 1734, 1834, 1860, 1883, 1885, 1892, 1895, 1907, 1914, 1916, 1923, 1947, 1966, 1967, 1968, 2019, 2076, 2078, 2109, 2145, 2150, 2174, 2186, 2203, 2204, 2282, 2324, 2336, 2351, 2359, 2390, 2395, 2406, 2467, 2571, 2583, 2599, 2628, 2683, 2692, 2712, 2762, 2763, 2770, 2791, 2843, 2858, 2874, 2921, 2926, 2959, 2973, 2997, 3033, 3044, 3060, 3079, 3083, 3160, 3175, 3176, 3204, 3255, 3317, 3358, 3365, 3386, 3408, 3481, 3489, 3508, 3538, 3591, 3788, 3809, 3851, 3897, 3911, 3967, 3996, 4002, 4014, 4020, 4021, 4027, 4029, 4033, 4034, 4074, 4121, 4144, 4166, 4226, 4239, 4246, 4252, 4260, 4273, 4308, 4347, 4381, 4641, 4741, 4765, 4881, 4896, 4902, 4967]\n"
     ]
    }
   ],
   "source": [
    "user_id = 4\n",
    "movies_rated_by_user_4 = ratings[ratings['userId'] == user_id]['movieId'].tolist()\n",
    "print(f\"Movies rated by userId {user_id}: {movies_rated_by_user_4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings matrix values for userId 4:\n",
      "MovieId 1: 0.0\n",
      "MovieId 2: 0.0\n",
      "MovieId 21: 1.0\n",
      "MovieId 32: 1.0\n",
      "MovieId 126: 1.0\n"
     ]
    }
   ],
   "source": [
    "user_idx = uid_to_idx[user_id]\n",
    "\n",
    "movie_ids = [1, 2, 21, 32, 126]\n",
    "ratings_values = {}\n",
    "for movie_id in movie_ids:\n",
    "    if movie_id in mid_to_idx:\n",
    "        movie_idx = mid_to_idx[movie_id]\n",
    "        value = ratings_matrix[user_idx, movie_idx]\n",
    "        ratings_values[movie_id] = value\n",
    "    else:\n",
    "        ratings_values[movie_id] = 0\n",
    "\n",
    "print(f\"Ratings matrix values for userId {user_id}:\")\n",
    "for movie_id, value in ratings_values.items():\n",
    "    print(f\"MovieId {movie_id}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5**. Now that you have a `ratings_matrix` in the correct format, let's save it in pickle format:\n",
    "- Create a variable `dst_dir` corresponding to the path of the folder `data/netflix` located at the root of the repository\n",
    "- **Verify that this is the correct path**\n",
    "- Save the ratings_matrix in pickle (as `ratings_matrix.pkl`) in this corresponding directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratings_matrix saved to data/netflix/ratings_matrix.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from scipy.sparse import save_npz\n",
    "\n",
    "dst_dir = os.path.join('data', 'netflix')\n",
    "\n",
    "if not os.path.exists(dst_dir):\n",
    "    os.makedirs(dst_dir)\n",
    "\n",
    "ratings_matrix_path = os.path.join(dst_dir, 'ratings_matrix.pkl')\n",
    "\n",
    "with open(ratings_matrix_path, 'wb') as f:\n",
    "    pickle.dump(ratings_matrix, f)\n",
    "\n",
    "print(f\"ratings_matrix saved to {ratings_matrix_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6**. Save also all mappings objects into pickle (`idx_to_mid`, `mid_to_idx`, `uid_to_idx`, `idx_to_uid`) as it will be useful for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx_to_mid saved to data/netflix/idx_to_mid.pkl\n",
      "mid_to_idx saved to data/netflix/mid_to_idx.pkl\n",
      "uid_to_idx saved to data/netflix/uid_to_idx.pkl\n",
      "idx_to_uid saved to data/netflix/idx_to_uid.pkl\n"
     ]
    }
   ],
   "source": [
    "idx_to_mid_path = os.path.join(dst_dir, 'idx_to_mid.pkl')\n",
    "mid_to_idx_path = os.path.join(dst_dir, 'mid_to_idx.pkl')\n",
    "uid_to_idx_path = os.path.join(dst_dir, 'uid_to_idx.pkl')\n",
    "idx_to_uid_path = os.path.join(dst_dir, 'idx_to_uid.pkl')\n",
    "\n",
    "with open(idx_to_mid_path, 'wb') as f:\n",
    "    pickle.dump(idx_to_mid, f)\n",
    "\n",
    "with open(mid_to_idx_path, 'wb') as f:\n",
    "    pickle.dump(mid_to_idx, f)\n",
    "\n",
    "with open(uid_to_idx_path, 'wb') as f:\n",
    "    pickle.dump(uid_to_idx, f)\n",
    "\n",
    "with open(idx_to_uid_path, 'wb') as f:\n",
    "    pickle.dump(idx_to_uid, f)\n",
    "\n",
    "print(f\"idx_to_mid saved to {idx_to_mid_path}\")\n",
    "print(f\"mid_to_idx saved to {mid_to_idx_path}\")\n",
    "print(f\"uid_to_idx saved to {uid_to_idx_path}\")\n",
    "print(f\"idx_to_uid saved to {idx_to_uid_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to next challenge now! 🍿"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
