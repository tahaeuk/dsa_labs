{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation - Model üçø"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://visithrastnik.si/uploads/tic/public/generic_list_item/6-kulturna_prireditev_v_avli_kulturnega_centra_zagorje_ob_savi.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, time for the exciting part! We will train a Machine Learning model based on our previous **ratings** sparse matrix, so that it creates a recommendation engine automatically! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load again the dataframe `movies` and `ratings`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1                   Adventure|Children|Fantasy  \n",
      "2                               Comedy|Romance  \n",
      "3                         Comedy|Drama|Romance  \n",
      "4                                       Comedy  \n",
      "   userId  movieId  rating  timestamp\n",
      "0       1        1     4.0  964982703\n",
      "1       1        3     4.0  964981247\n",
      "2       1        6     4.0  964982224\n",
      "3       1       47     5.0  964983815\n",
      "4       1       50     5.0  964982931\n"
     ]
    }
   ],
   "source": [
    "### TODO: Load the movies and ratings datasets\n",
    "movies = pd.read_csv('ml-latest-small/movies.csv')\n",
    "ratings = pd.read_csv('ml-latest-small/ratings.csv')\n",
    "\n",
    "# Display the first few rows of each DataFrame to ensure they are loaded correctly\n",
    "print(movies.head())\n",
    "print(ratings.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1**. Start by loading all the pickle you saved during last challenge: `ratings_matrix`, `idx_to_mid`, `mid_to_idx`, `uid_to_idx`, `idx_to_uid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickles loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Specify the directory where the pickled files are saved\n",
    "src_dir = os.path.join('data', 'netflix')\n",
    "\n",
    "# Load ratings_matrix\n",
    "ratings_matrix_path = os.path.join(src_dir, 'ratings_matrix.pkl')\n",
    "with open(ratings_matrix_path, 'rb') as f:\n",
    "    ratings_matrix = pickle.load(f)\n",
    "\n",
    "# Load idx_to_mid\n",
    "idx_to_mid_path = os.path.join(src_dir, 'idx_to_mid.pkl')\n",
    "with open(idx_to_mid_path, 'rb') as f:\n",
    "    idx_to_mid = pickle.load(f)\n",
    "\n",
    "# Load mid_to_idx\n",
    "mid_to_idx_path = os.path.join(src_dir, 'mid_to_idx.pkl')\n",
    "with open(mid_to_idx_path, 'rb') as f:\n",
    "    mid_to_idx = pickle.load(f)\n",
    "\n",
    "# Load uid_to_idx\n",
    "uid_to_idx_path = os.path.join(src_dir, 'uid_to_idx.pkl')\n",
    "with open(uid_to_idx_path, 'rb') as f:\n",
    "    uid_to_idx = pickle.load(f)\n",
    "\n",
    "# Load idx_to_uid\n",
    "idx_to_uid_path = os.path.join(src_dir, 'idx_to_uid.pkl')\n",
    "with open(idx_to_uid_path, 'rb') as f:\n",
    "    idx_to_uid = pickle.load(f)\n",
    "\n",
    "# Confirming loading\n",
    "print(\"Pickles loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2**. Because the dataset is slightly different from what we have been used to (X as features, y as target), the usual `train_test_split` method from scikit-learn does not apply.\n",
    "\n",
    "Hopefully, `lightfm` comes with a `random_train_test_split` located into `cross_validation` dedicated to this usecase üôÇ\n",
    "\n",
    "Split the data randomly into a `train` matrix and a `test` matrix with 20% of interactions into the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train matrix: (610, 9724)\n",
      "Shape of test matrix: (610, 9724)\n"
     ]
    }
   ],
   "source": [
    "from lightfm.cross_validation import random_train_test_split\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train, test = random_train_test_split(ratings_matrix, test_percentage=0.2, random_state=42)\n",
    "\n",
    "# Confirm the shapes of train and test matrices\n",
    "print(\"Shape of train matrix:\", train.shape)\n",
    "print(\"Shape of test matrix:\", test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3**. Train a LightFM model for 10 epochs. You can use the parameter `loss=\"warp\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training completed.\n"
     ]
    }
   ],
   "source": [
    "from lightfm import LightFM\n",
    "\n",
    "# Create a LightFM model with WARP loss\n",
    "model = LightFM(loss='warp')\n",
    "\n",
    "# Train the model for 10 epochs\n",
    "model.fit(train, epochs=10)\n",
    "\n",
    "print(\"Model training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4**. Evaluate your model on your test set. You can use the `precision_at_k` metric implemented in the LightFM library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision at k=5: 0.1013\n"
     ]
    }
   ],
   "source": [
    "from lightfm.evaluation import precision_at_k\n",
    "\n",
    "# Evaluate precision at k\n",
    "precision = precision_at_k(model, test, k=5).mean()\n",
    "\n",
    "print(f\"Precision at k=5: {precision:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5**. What does the attribute `item_embeddings` of `model` contains?  This will be the heart of your recommendation engine! üíü So make sure you understand fully what it contains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The item_embeddings attribute of the LightFM model contains the learned latent representations of the items in the dataset. These embeddings represent the underlying characteristics or features of each item, which the model has learned during the training process. The embeddings are represented as a NumPy array where each row corresponds to the embedding vector of an item.\n",
    "\n",
    "These embeddings are crucial for the recommendation engine because they encode the relationships between items in the latent space. By measuring the similarity between item embeddings, the model can identify items that are similar or related to each other. This similarity information is then used to make recommendations to users based on their interactions or preferences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6**. We just trained a model that factorized our ratings matrix into a U matrix of shape (n_users, no_components) : `model.user_embeddings` ; and V matrix of shape (n_movies, no_components) : `model.item_embeddings`).\n",
    "\n",
    "Now we want to compute **similarity between each pair of movies**.\n",
    "\n",
    "> üî¶ **Hint**: For the similarity distance we can either use `cosine_similarity` function or `pearson_similarity`:\n",
    "> - **Cosine similarity** between two vectors, or matrices X and Y is given by:\n",
    "> ``` python\n",
    "> from sklearn.metrics.pairwise import cosine_similarity\n",
    "> cosine_similarity(X, Y)\n",
    "> ```\n",
    "> - **Pearson similarity** between two vectors, or matrices X and Y is given by:\n",
    "> ``` python\n",
    "> import numpy as np\n",
    "> np.corrcoef(X, Y)\n",
    "> ```\n",
    "\n",
    "Compute the `similarity_scores` of size (n_movies, n_movies), containing for each element (i, j) the similarity between movie of index i and movie of index j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of similarity_scores matrix: (9724, 9724)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Compute cosine similarity between item embeddings\n",
    "similarity_scores = cosine_similarity(model.item_embeddings)\n",
    "\n",
    "# Print the shape of the similarity_scores matrix\n",
    "print(\"Shape of similarity_scores matrix:\", similarity_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of similarity_scores matrix: (9724, 9724)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Compute Pearson similarity between item embeddings\n",
    "similarity_scores = np.corrcoef(model.item_embeddings)\n",
    "\n",
    "# Print the shape of the similarity_scores matrix\n",
    "print(\"Shape of similarity_scores matrix:\", similarity_scores.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7**. For movie of idx 20, what are the idx of the 10 most similar movies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of the 10 most similar movies:\n",
      "[1027  162   15  728  987  401 2462 2199   70   84]\n"
     ]
    }
   ],
   "source": [
    "movie_idx = 20\n",
    "\n",
    "movie_similarity_scores = similarity_scores[movie_idx]\n",
    "\n",
    "most_similar_indices = movie_similarity_scores.argsort()[-11:-1][::-1]\n",
    "\n",
    "print(\"Indices of the 10 most similar movies:\")\n",
    "print(most_similar_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8**. Let's now test our engine! Suppose we have an user that likes **Toy Story** üß∏ (movie_id = 1). Which movies would you recommend to that user? In other words, which movies are the most similar to the movie Toy Story \n",
    "\n",
    "> ‚ö†Ô∏è **Warning**: Remember that your `similarity_scores` works with `idx` and you have the `movie_id` associated to your movie.\n",
    "\n",
    "Retrieve the **top 5 recommendations**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommendations for a user who likes Toy Story:\n",
      "[480, 48, 588, 589, 780]\n"
     ]
    }
   ],
   "source": [
    "toy_story_idx = 1\n",
    "\n",
    "toy_story_index = idx_to_mid[toy_story_idx]\n",
    "\n",
    "toy_story_similarity_scores = similarity_scores[toy_story_index]\n",
    "\n",
    "most_similar_indices = toy_story_similarity_scores.argsort()[-6:-1][::-1]\n",
    "\n",
    "top_5_recommendations = [idx_to_mid[idx] for idx in most_similar_indices]\n",
    "\n",
    "print(\"Top 5 recommendations for a user who likes Toy Story:\")\n",
    "print(top_5_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the next step is to **deploy your model**, you need now to: \n",
    "\n",
    "**Q9**. Save your `similarity_scores` into pickle format. Save also `movies` DataFrame into pickle format. Save them at the `data/netflix` directory at the root of the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity scores saved to data/netflix/similarity_scores.pkl\n",
      "Movies DataFrame saved to data/netflix/movies.pkl\n"
     ]
    }
   ],
   "source": [
    "dst_dir = os.path.join('data', 'netflix')\n",
    "\n",
    "similarity_scores_path = os.path.join(dst_dir, 'similarity_scores.pkl')\n",
    "with open(similarity_scores_path, 'wb') as f:\n",
    "    pickle.dump(similarity_scores, f)\n",
    "\n",
    "movies_path = os.path.join(dst_dir, 'movies.pkl')\n",
    "movies.to_pickle(movies_path)\n",
    "\n",
    "print(f\"Similarity scores saved to {similarity_scores_path}\")\n",
    "print(f\"Movies DataFrame saved to {movies_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10**. Encapsulate the previous code into functions, especially you will need:\n",
    "- `get_sim_scores(mid)` function that returns the vector of the similarity scores `sims` between a movie `mid` and all the other movies\n",
    "- `get_ranked_recos(sims)` that returns for a vector of similarity scores `sims` the list of all ranked recommendations (n_movies) (from most recommended to least recommended) - in the format list of (mid, score, name) tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked recommendations for movie_id 20\n",
      "Movie ID: 20, Similarity Score: 1.0000, Name: Get Shorty (1995)\n",
      "Movie ID: 1027, Similarity Score: 0.9712, Name: Dracula (Bram Stoker's Dracula) (1992)\n",
      "Movie ID: 162, Similarity Score: 0.9704, Name: Scarlet Letter, The (1995)\n",
      "Movie ID: 15, Similarity Score: 0.9697, Name: Casino (1995)\n",
      "Movie ID: 728, Similarity Score: 0.9685, Name: Giant (1956)\n",
      "Movie ID: 987, Similarity Score: 0.9646, Name: This Is Spinal Tap (1984)\n",
      "Movie ID: 401, Similarity Score: 0.9645, Name: Getting Even with Dad (1994)\n",
      "Movie ID: 2462, Similarity Score: 0.9625, Name: Boondock Saints, The (2000)\n",
      "Movie ID: 2199, Similarity Score: 0.9605, Name: Drunken Master (Jui kuen) (1978)\n",
      "Movie ID: 70, Similarity Score: 0.9599, Name: Crossing Guard, The (1995)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "def load_similarity_scores(dst_dir):\n",
    "    \"\"\"Load the similarity scores matrix.\"\"\"\n",
    "    similarity_scores_path = os.path.join(dst_dir, 'similarity_scores.pkl')\n",
    "    with open(similarity_scores_path, 'rb') as f:\n",
    "        similarity_scores = pickle.load(f)\n",
    "    return similarity_scores\n",
    "\n",
    "def load_movies(dst_dir):\n",
    "    \"\"\"Load the movies DataFrame.\"\"\"\n",
    "    movies_path = os.path.join(dst_dir, 'movies.pkl')\n",
    "    movies = pd.read_pickle(movies_path)\n",
    "    return movies\n",
    "\n",
    "def get_sim_scores(mid):\n",
    "    \"\"\"Get the vector of similarity scores between a movie and all other movies.\"\"\"\n",
    "    return similarity_scores[mid]\n",
    "\n",
    "def get_ranked_recos(sims, movies):\n",
    "    \"\"\"\n",
    "    Get the list of all ranked recommendations (from most recommended to least recommended).\n",
    "\n",
    "    Args:\n",
    "    sims (numpy.ndarray): Vector of similarity scores.\n",
    "    movies (pandas.DataFrame): DataFrame containing movie information.\n",
    "\n",
    "    Returns:\n",
    "    list: List of (mid, score, name) tuples representing ranked recommendations.\n",
    "    \"\"\"\n",
    "    sorted_indices = sims.argsort()[::-1]\n",
    "    ranked_recos = []\n",
    "    for idx in sorted_indices:\n",
    "        try:\n",
    "            name = movies.loc[idx, 'title']\n",
    "            ranked_recos.append((idx, sims[idx], name))\n",
    "        except KeyError:\n",
    "            print(f\"Movie ID {idx} does not have a title.\")\n",
    "    return ranked_recos\n",
    "\n",
    "dst_dir = os.path.join('data', 'netflix')\n",
    "\n",
    "similarity_scores = load_similarity_scores(dst_dir)\n",
    "movies = load_movies(dst_dir)\n",
    "\n",
    "mid = 20\n",
    "sims = get_sim_scores(mid)\n",
    "ranked_recos = get_ranked_recos(sims, movies)\n",
    "print(\"Ranked recommendations for movie_id\", mid)\n",
    "for idx, score, name in ranked_recos[:10]:\n",
    "    print(f\"Movie ID: {idx}, Similarity Score: {score:.4f}, Name: {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have extra time, feel free now to improve your recommendation engine!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
